# -*- coding: utf-8 -*-
"""final_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NZWYHIJu7a93N6DABVF_R6o-ujBqclDB
"""











!pip install Pydub
!pip install glob2
import glob
import os

from pydub import AudioSegment
sound = AudioSegment.from_mp3("/content/drive/MyDrive/work/e.mp3")
sound.export("/content/drive/MyDrive/work/store"+"e.wav", format="wav")

import tensorflow as tf
import tensorflow_hub as hub
import numpy as np
import csv

import matplotlib.pyplot as plt
from IPython.display import Audio
from scipy.io import wavfile

model = hub.load('https://tfhub.dev/google/yamnet/1')

def class_names_from_csv(class_map_csv_text):
  class_names = []
  with tf.io.gfile.GFile(class_map_csv_text) as csvfile:
    reader = csv.DictReader(csvfile)
    for row in reader:
      class_names.append(row['display_name'])

  return class_names

class_map_path = model.class_map_path().numpy()
class_names = class_names_from_csv(class_map_path)

from scipy import signal as sg

def ensure_sample_rate(original_sample_rate, waveform,
                       desired_sample_rate=16000):
  if original_sample_rate != desired_sample_rate:
    desired_length = int(round(float(len(waveform)) /
                               original_sample_rate * desired_sample_rate))
    waveform = sg.resample(waveform, desired_length)
  return desired_sample_rate, waveform

source_audio = '/content/drive/MyDrive/work/storee.wav'
sample_rate, wav_data = wavfile.read(source_audio, 'rb')
sample_rate, wav_data = ensure_sample_rate(sample_rate, wav_data)

# Show some basic information about the audio.
time = len(wav_data)/sample_rate
print(time)
audio_set=list()
p1=0
p2=5000
k=0
temp_audio=AudioSegment.from_wav(source_audio)
aud=temp_audio[p1:p2]
while(p2<time*1000-p2):
  temp_audio=AudioSegment.from_wav(source_audio)
  aud=temp_audio[p1:p2]
  aud.export("/content/drive/MyDrive/work/audio/"+str(k)+".wav", format="wav")
  k+=1
  p1+=5000
  p2+=5000
aud=temp_audio[p2:time*1000]
aud.export('/content/drive/MyDrive/work/audio/'+str(k)+'.wav', format="wav")

!pip install glob2
import glob

j=glob.glob('/content/drive/MyDrive/work/audio/*.wav')
output=[]
for i in j:
  p=os.path.splitext(i)[0]+".wav"
  sample_rate, wav_data = wavfile.read(p, 'rb')
  sample_rate, wav_data = ensure_sample_rate(sample_rate, wav_data)
  waveform = wav_data / tf.int16.max
  scores, embeddings, spectrogram = model(waveform)
  scores_np = scores.numpy()
  spectrogram_np = spectrogram.numpy()
  infered_class = class_names[scores_np.mean(axis=0).argmax()]
  output.append(infered_class)
print(output)





